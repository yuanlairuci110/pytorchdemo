{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x5299610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]])\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  \n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'forty', 'winters', 'shall', 'besiege', 'thy', 'brow,', 'And', 'dig', 'deep', 'trenches', 'in', 'thy', \"beauty's\", 'field,', 'Thy', \"youth's\", 'proud', 'livery', 'so', 'gazed', 'on', 'now,', 'Will', 'be', 'a', \"totter'd\", 'weed', 'of', 'small', 'worth', 'held:', 'Then', 'being', 'asked,', 'where', 'all', 'thy', 'beauty', 'lies,', 'Where', 'all', 'the', 'treasure', 'of', 'thy', 'lusty', 'days;', 'To', 'say,', 'within', 'thine', 'own', 'deep', 'sunken', 'eyes,', 'Were', 'an', 'all-eating', 'shame,', 'and', 'thriftless', 'praise.', 'How', 'much', 'more', 'praise', \"deserv'd\", 'thy', \"beauty's\", 'use,', 'If', 'thou', 'couldst', 'answer', \"'This\", 'fair', 'child', 'of', 'mine', 'Shall', 'sum', 'my', 'count,', 'and', 'make', 'my', 'old', \"excuse,'\", 'Proving', 'his', 'beauty', 'by', 'succession', 'thine!', 'This', 'were', 'to', 'be', 'new', 'made', 'when', 'thou', 'art', 'old,', 'And', 'see', 'thy', 'blood', 'warm', 'when', 'thou', \"feel'st\", 'it', 'cold.']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new', 'fair', \"youth's\", 'worth', 'so', 'Shall', 'field,', 'Will', 'days;', \"'This\", 'thine', 'art', 'And', 'sum', 'beauty', 'were', 'How', \"beauty's\", 'This', 'succession', 'use,', 'being', \"deserv'd\", 'it', 'held:', 'my', 'lies,', 'a', 'Were', 'old', 'sunken', 'thine!', 'asked,', 'shame,', 'much', 'an', 'Thy', 'shall', 'lusty', 'answer', 'the', 'own', 'now,', 'If', 'treasure', 'to', 'see', 'Proving', 'Then', 'Where', 'mine', 'trenches', 'when', 'child', \"totter'd\", 'count,', 'praise.', 'blood', 'by', 'old,', 'weed', 'all', 'When', 'livery', 'thou', 'winters', 'more', 'dig', 'where', 'in', 'warm', 'his', 'besiege', 'To', 'thy', 'couldst', 'say,', 'brow,', 'all-eating', 'be', 'eyes,', 'of', 'and', \"feel'st\", 'within', 'made', \"excuse,'\", 'gazed', 'make', 'cold.', 'proud', 'small', 'praise', 'forty', 'thriftless', 'deep', 'on'}\n{'new': 0, 'fair': 1, \"youth's\": 2, 'worth': 3, 'so': 4, 'Shall': 5, 'field,': 6, 'Will': 7, 'days;': 8, \"'This\": 9, 'thine': 10, 'art': 11, 'And': 12, 'sum': 13, 'beauty': 14, 'were': 15, 'How': 16, \"beauty's\": 17, 'This': 18, 'succession': 19, 'use,': 20, 'being': 21, \"deserv'd\": 22, 'it': 23, 'held:': 24, 'my': 25, 'lies,': 26, 'a': 27, 'Were': 28, 'old': 29, 'sunken': 30, 'thine!': 31, 'asked,': 32, 'shame,': 33, 'much': 34, 'an': 35, 'Thy': 36, 'shall': 37, 'lusty': 38, 'answer': 39, 'the': 40, 'own': 41, 'now,': 42, 'If': 43, 'treasure': 44, 'to': 45, 'see': 46, 'Proving': 47, 'Then': 48, 'Where': 49, 'mine': 50, 'trenches': 51, 'when': 52, 'child': 53, \"totter'd\": 54, 'count,': 55, 'praise.': 56, 'blood': 57, 'by': 58, 'old,': 59, 'weed': 60, 'all': 61, 'When': 62, 'livery': 63, 'thou': 64, 'winters': 65, 'more': 66, 'dig': 67, 'where': 68, 'in': 69, 'warm': 70, 'his': 71, 'besiege': 72, 'To': 73, 'thy': 74, 'couldst': 75, 'say,': 76, 'brow,': 77, 'all-eating': 78, 'be': 79, 'eyes,': 80, 'of': 81, 'and': 82, \"feel'st\": 83, 'within': 84, 'made': 85, \"excuse,'\": 86, 'gazed': 87, 'make': 88, 'cold.': 89, 'proud': 90, 'small': 91, 'praise': 92, 'forty': 93, 'thriftless': 94, 'deep': 95, 'on': 96}\n"
     ]
    }
   ],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "print(vocab)\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520.2846329212189, 517.7636170387268, 515.2583310604095, 512.7692008018494, 510.29487800598145, 507.83550453186035, 505.3903856277466, 502.95680379867554, 500.53439807891846, 498.1221959590912]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process.', 'Computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers.', 'As', 'they', 'evolve,', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data.', 'The', 'evolution', 'of', 'a', 'process', 'is', 'directed', 'by', 'a', 'pattern', 'of', 'rules', 'called', 'a', 'program.', 'People', 'create', 'programs', 'to', 'direct', 'processes.', 'In', 'effect,', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells.']\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data.', 'study', 'beings', 'we', 'We', 'create', 'they', 'things', 'computers.', 'processes.', 'about', 'As', 'effect,', 'are', 'process.', 'computer', 'rules', 'by', 'programs', 'a', 'spirits', 'In', 'Computational', 'pattern', 'that', 'of', 'program.', 'with', 'other', 'People', 'directed', 'abstract', 'spells.', 'computational', 'inhabit', 'our', 'evolution', 'idea', 'direct', 'the', 'is', 'evolve,', 'called', 'to', 'The', 'conjure', 'process', 'processes', 'manipulate'}\n49\n"
     ]
    }
   ],
   "source": [
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
